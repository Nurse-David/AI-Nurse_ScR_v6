{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyM0OmAGB36VcX0Or72jKti/"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yn5FKEFmm52p",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1747618509127,
     "user_tz": -720,
     "elapsed": 29966,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "1dd6dc00-b1e1-4b66-b909-ad0b3ee7e998",
    "cellView": "form"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- PYTHON ENVIRONMENT FINGERPRINT ---\n",
      "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
      "Platform      : Linux-6.1.123+-x86_64-with-glibc2.35\n",
      "CWD           : /content\n",
      "Locale        : en_US.UTF-8\n",
      "Datetime UTC  : 2025-05-19T01:34:39.834735Z\n",
      "Datetime NZDT : 2025-05-19T13:34:39.834343+12:00\n",
      "- Required Pip Package Versions -\n",
      "PyMuPDF: 1.25.5\n",
      "pdfplumber: 0.11.6\n",
      "pandas: 2.2.2\n",
      "tqdm: 4.67.1\n",
      "tiktoken: 0.9.0\n",
      "openai: 1.78.1\n",
      "requests: 2.32.3\n",
      "pyyaml: 6.0.2\n",
      "--- End Block 1 ---\n"
     ]
    }
   ],
   "source": [
    "# @title [Block 1] Install & Verify All Pipeline Libraries (+Deprecation-safe, Audit Logging, Timezone)\n",
    "# Version 6.2.5\n",
    "# v6.0: Added tiktoken and improved environment/version printouts.\n",
    "# v6.1: Suppresses noisy pdfminer/pdfplumber warnings, writes requirements.txt, more clear reviewer messages.\n",
    "# v6.2: Audit log, fail-closed preflight, critical package enforcement, more robust error/warning audit output.\n",
    "# v6.2.3: NZDT/UTC timestamp for chain-of-custody, audit-logging enhanced.\n",
    "# v6.2.4: Fully removes pkg_resources, uses importlib.metadata for requirements/version print.\n",
    "# v6.2.5: [BUGFIX] Corrects `required_packages` unpacking (now always 3-element tuples).\n",
    "#\n",
    "# Block Summary\n",
    "#\n",
    "# - Installs/verifies all dependencies, fails closed if any are missing.\n",
    "# - Suppresses pdfminer/pdfplumber UserWarnings.\n",
    "# - Prints all required package versions, Python/platform/locale.\n",
    "# - Records UTC and NZDT timestamps for fixity audit.\n",
    "# - Writes requirements.txt and audit/block1_env_fingerprint.jsonl.\n",
    "# - Uses importlib.metadata (not pkg_resources) everywhere.\n",
    "\n",
    "import sys, platform, subprocess, os, locale, hashlib, json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Timezone handling ----\n",
    "try:\n",
    "    import zoneinfo\n",
    "    TZ_NZ = zoneinfo.ZoneInfo(\"Pacific/Auckland\")\n",
    "    now_nzdt = datetime.now(TZ_NZ)\n",
    "except Exception:\n",
    "    TZ_NZ = None\n",
    "    now_nzdt = None\n",
    "now_utc = datetime.utcnow()\n",
    "now_utc_iso = now_utc.isoformat() + \"Z\"\n",
    "now_nzdt_iso = (now_nzdt.isoformat() if now_nzdt else \"Unavailable\")\n",
    "\n",
    "# --------- Audit log helper ----------\n",
    "def sha256_file(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return hashlib.sha256(f.read()).hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def write_audit_log(data, path=\"audit/block1_env_fingerprint.jsonl\"):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# --------- Suppress noisy PDF warnings ----------\n",
    "import logging, warnings\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pdfminer.pdfpage\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --------- REQUIRED/IMPORT names and install names (pip_name, import_name, dist_name) ----------\n",
    "required_packages = [\n",
    "    (\"PyMuPDF\", \"fitz\", \"pymupdf\"),\n",
    "    (\"pdfplumber\", \"pdfplumber\", \"pdfplumber\"),\n",
    "    (\"pandas\", \"pandas\", \"pandas\"),\n",
    "    (\"tqdm\", \"tqdm\", \"tqdm\"),\n",
    "    (\"tiktoken\", \"tiktoken\", \"tiktoken\"),\n",
    "    (\"openai\", \"openai\", \"openai\"),\n",
    "    (\"requests\", \"requests\", \"requests\"),\n",
    "    (\"pyyaml\", \"yaml\", \"pyyaml\"),\n",
    "]\n",
    "\n",
    "# --------- Audit log object ----------\n",
    "block1_audit = {\n",
    "    \"step\": \"block1_install_and_env\",\n",
    "    \"timestamp_utc\": now_utc_iso,\n",
    "    \"timestamp_nzdt\": now_nzdt_iso,\n",
    "    \"python_version\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"cwd\": str(Path.cwd()),\n",
    "    \"user\": os.environ.get(\"USER\", os.environ.get(\"USERNAME\", \"unknown\")),\n",
    "    \"locale\": \"\",\n",
    "    \"requirements_txt_hash\": None,\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "}\n",
    "\n",
    "try:\n",
    "    block1_audit[\"locale\"] = locale.setlocale(locale.LC_ALL, '')\n",
    "except Exception:\n",
    "    block1_audit[\"warnings\"].append(\"Could not detect locale.\")\n",
    "\n",
    "# --------- Preflight: install/verify packages, fail-closed if not present ----------\n",
    "def pip_install_package(pip_name, import_name):\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name])\n",
    "            __import__(import_name)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "failed_pkgs = []\n",
    "for pip_name, import_name, dist_name in required_packages:\n",
    "    result = pip_install_package(pip_name, import_name)\n",
    "    if result is not True:\n",
    "        failed_pkgs.append((pip_name, result))\n",
    "if failed_pkgs:\n",
    "    print(\"\\n[CRITICAL ERROR] Could not install required dependencies:\")\n",
    "    for pip_name, err in failed_pkgs:\n",
    "        print(f\" - {pip_name}: {err}\")\n",
    "        block1_audit[\"errors\"].append(f\"{pip_name}: {err}\")\n",
    "    write_audit_log(block1_audit)\n",
    "    print(\"Reviewer Action:\\n - Please verify internet access and pip availability.\\n - Rerun this block when resolved.\\n - Error log is saved to audit/block1_env_fingerprint.jsonl.\")\n",
    "    raise SystemExit(\"Block 1 failed closed due to missing required libraries.\")\n",
    "\n",
    "# --------- Write requirements.txt and hash it for audit trail ----------\n",
    "try:\n",
    "    try:\n",
    "        import importlib.metadata as importlib_metadata\n",
    "    except ImportError:\n",
    "        import importlib_metadata # type: ignore\n",
    "    dists = sorted(importlib_metadata.distributions(), key=lambda d: (d.metadata[\"Name\"] if \"Name\" in d.metadata else d._path.name).lower())\n",
    "    with open(\"requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for dist in dists:\n",
    "            name = dist.metadata[\"Name\"] if \"Name\" in dist.metadata else dist._path.name\n",
    "            version = dist.version\n",
    "            f.write(f\"{name}=={version}\\n\")\n",
    "    req_hash = sha256_file(\"requirements.txt\")\n",
    "    block1_audit[\"requirements_txt_hash\"] = req_hash\n",
    "except Exception as e:\n",
    "    msg = f\"Could not write requirements.txt: {e}\"\n",
    "    block1_audit[\"warnings\"].append(msg)\n",
    "    print(\"[WARN]\", msg)\n",
    "\n",
    "# --------- Print python/environment/time details ----------\n",
    "print(\"--- PYTHON ENVIRONMENT FINGERPRINT ---\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform      : {platform.platform()}\")\n",
    "print(f\"CWD           : {Path.cwd()}\")\n",
    "try:\n",
    "    print(f\"Locale        : {locale.setlocale(locale.LC_ALL, '')}\")\n",
    "except:\n",
    "    print(\"Locale        : [Could not detect locale]\")\n",
    "print(f\"Datetime UTC  : {now_utc_iso}\")\n",
    "print(f\"Datetime NZDT : {now_nzdt_iso if now_nzdt else '[Zoneinfo not installed]'}\")\n",
    "print(\"- Required Pip Package Versions -\")\n",
    "for pip_name, import_name, dist_name in required_packages:\n",
    "    try:\n",
    "        version = importlib_metadata.version(dist_name)\n",
    "        print(f\"{pip_name}: {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{pip_name}: NOT INSTALLED or version not found ({e})\")\n",
    "        block1_audit[\"warnings\"].append(f\"{pip_name}: not found ({e})\")\n",
    "print(\"--- End Block 1 ---\")\n",
    "write_audit_log(block1_audit)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title [Block 2] Define Project Paths, Mount Drive, NZDT Run Folder, Print PDF Corpus Summary, Interactive Config Confirmation, Save pipeline_env.json (v6.2.5)\n",
    "#\n",
    "# ----------- [Version 6.2.5] -----------\n",
    "# v6.0: Sets up all pipeline dirs and run/output/audit folders.\n",
    "# v6.1: Reviewer-friendly summary and robust error checks.\n",
    "# v6.2: Audit logging, fail-closed config, explicit directory setup, next-step guidance.\n",
    "# v6.2.3: NZDT time/fixity, prints cd/CONFIG_PATH helper, logs NZDT+UTC.\n",
    "# v6.2.5: On completion, writes all global pipeline folder/ID variables to pipeline_env.json for use in all future blocks (NO search or input needed).\n",
    "#\n",
    "# ----------- [Block Summary] -----------\n",
    "# - Sets up and prints all pipeline directories and run/output/audit folders with NZDT/UTC timestamp for fixity.\n",
    "# - Creates/validates config.yaml (if missing, prints code-grouped YAML, reviewer Y/N pause option).\n",
    "# - Writes all project/run path/globals to pipeline_env.json so all next blocks just reload this\u2014NO searching, prompt, or ambiguity.\n",
    "# - Reviewer guidance, printout, and summary for PI/repro.\n",
    "# - Audit log written with full NZDT/UTC provenance.\n",
    "#\n",
    "# ----------- [Start of Code] -----------\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Timezone safe run creation ---\n",
    "try:\n",
    "    import zoneinfo\n",
    "    TZ_NZ = zoneinfo.ZoneInfo(\"Pacific/Auckland\")\n",
    "    now_nzdt = datetime.now(TZ_NZ)\n",
    "    NOW_STR = now_nzdt.strftime('%y%m%d_%H%M')\n",
    "    now_utc = datetime.utcnow()\n",
    "    NZDT_LABEL = now_nzdt.isoformat()\n",
    "    UTC_LABEL = now_utc.isoformat() + \"Z\"\n",
    "except Exception:\n",
    "    TZ_NZ = None\n",
    "    now_nzdt = None\n",
    "    NOW_STR = datetime.utcnow().strftime('%y%m%d_%H%M')\n",
    "    now_utc = datetime.utcnow()\n",
    "    NZDT_LABEL = \"Unavailable\"\n",
    "    UTC_LABEL = now_utc.isoformat() + \"Z\"\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = Path('/content/drive/My Drive/Pilot') if IN_COLAB else Path.cwd() / \"Pilot\"\n",
    "PDF_DIR = PROJECT_ROOT / 'PDFs'\n",
    "RUN_ID = f\"Nurse-AI_ScR_{NOW_STR}\"\n",
    "RUN_DIR = PROJECT_ROOT / RUN_ID\n",
    "OPERATIONAL_DIR      = RUN_DIR / 'operational'\n",
    "AI_ARTIFACTS_DIR     = RUN_DIR / 'ai_artifacts'\n",
    "REVIEWER_CONTENT_DIR = RUN_DIR / 'reviewer_content'\n",
    "METRICS_DIR          = RUN_DIR / 'metrics'\n",
    "AUDIT_DIR            = RUN_DIR / 'audit'\n",
    "ISSUES_DIR           = RUN_DIR / 'issues'\n",
    "TESTS_DIR            = RUN_DIR / 'tests'\n",
    "for d in [RUN_DIR, OPERATIONAL_DIR, AI_ARTIFACTS_DIR, REVIEWER_CONTENT_DIR, METRICS_DIR, AUDIT_DIR, ISSUES_DIR, TESTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdfs_list = sorted(PDF_DIR.glob('*.pdf')) if PDF_DIR.exists() else []\n",
    "n_pdfs = len(pdfs_list)\n",
    "\n",
    "CONFIG_PATH = OPERATIONAL_DIR / \"config.yaml\"\n",
    "MANIFEST_PATH = OPERATIONAL_DIR / \"manifest.csv\"\n",
    "CONFIG_PARAMETERS = {\n",
    "    'llm_model': 'gpt-4.1-2025-04-14',\n",
    "    'openai_key_envvar': 'OPENAI_API_KEY',\n",
    "    'embedding_model': 'text-embedding-3-large',\n",
    "    'chunk_sizes': [500, 5000],\n",
    "    'chunk_overlaps': {500: 100, 5000: 500},\n",
    "    'tiktoken_encoding': 'cl100k_base',\n",
    "    'num_pdfs': n_pdfs,\n",
    "    'temperature_schedule': [0.0, 0.0, 0.0, 0.1, 0.2],\n",
    "    'max_context_tokens': 1000000,\n",
    "    'max_synthesis_tokens': 1000000,\n",
    "    'run_timestamp': NZDT_LABEL,\n",
    "    'run_id': RUN_ID,\n",
    "    'use_grobid': True,\n",
    "    'grobid_url': \"http://localhost:8070/api/processHeaderDocument\",\n",
    "    'use_crossref': True,\n",
    "    'use_openalex': True,\n",
    "    'allow_internet': False,\n",
    "    'allow_dynamic_expansion': False,\n",
    "}\n",
    "CONFIG_PATHS = {\n",
    "    'pdf_dir': str(PDF_DIR),\n",
    "    'run_dir': str(RUN_DIR),\n",
    "    'project_root': str(PROJECT_ROOT),\n",
    "    'manifest_path': str(MANIFEST_PATH),\n",
    "    'operational_dir': str(OPERATIONAL_DIR),\n",
    "    'ai_artifacts_dir': str(AI_ARTIFACTS_DIR),\n",
    "    'reviewer_content_dir': str(REVIEWER_CONTENT_DIR),\n",
    "    'metrics_dir': str(METRICS_DIR),\n",
    "    'audit_dir': str(AUDIT_DIR),\n",
    "    'issues_dir': str(ISSUES_DIR),\n",
    "    'tests_dir': str(TESTS_DIR),\n",
    "}\n",
    "DEFAULT_CONFIG = {**CONFIG_PARAMETERS, **CONFIG_PATHS}\n",
    "config_yaml_content = \"# --- Pipeline Parameters and Tools ---\\n\"\n",
    "config_yaml_content += yaml.dump(CONFIG_PARAMETERS, sort_keys=False, default_flow_style=False)\n",
    "config_yaml_content += \"\\n# --- Directories, Paths, and Filenames ---\\n\"\n",
    "config_yaml_content += yaml.dump(CONFIG_PATHS, sort_keys=False, default_flow_style=False)\n",
    "\n",
    "missing_config = False\n",
    "user_choice = None\n",
    "if not CONFIG_PATH.exists():\n",
    "    missing_config = True\n",
    "    with open(CONFIG_PATH, \"w\") as f:\n",
    "        f.write(config_yaml_content)\n",
    "    print(f\"\\n[NOTICE] config.yaml was NOT found and a full template was created at:\\n  {CONFIG_PATH}\")\n",
    "    print(\"------ config.yaml TEMPLATE CONTENT ------\")\n",
    "    print(config_yaml_content)\n",
    "    print(\"-----------------------------------------\")\n",
    "    try:\n",
    "        user_choice = input(\"Would you like to edit config.yaml before continuing? [Y/N]: \").strip().lower()\n",
    "    except Exception:\n",
    "        user_choice = \"n\"\n",
    "    if user_choice == \"y\":\n",
    "        print(f\"Pause here and edit config.yaml at:\\n  {CONFIG_PATH}\\nThen run this block again when finished.\")\n",
    "        block2_audit = {\n",
    "            \"step\": \"block2_dir_and_config_preflight\",\n",
    "            \"timestamp_nzdt\": NZDT_LABEL,\n",
    "            \"timestamp_utc\": UTC_LABEL,\n",
    "            \"user_decision\": \"pause_to_edit_config\",\n",
    "            \"config_path\": str(CONFIG_PATH),\n",
    "        }\n",
    "        audit_log_path = AUDIT_DIR / \"block2_dirsetup_preflight.jsonl\"\n",
    "        with open(audit_log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(block2_audit, ensure_ascii=False) + \"\\n\")\n",
    "        raise RuntimeError(\"[BLOCK 2 PAUSED] Edit config.yaml and rerun this cell.\")\n",
    "    else:\n",
    "        print(\"Continuing with the generated config.yaml as shown above.\")\n",
    "else:\n",
    "    print(f\"[OK] config.yaml found: {CONFIG_PATH}\")\n",
    "\n",
    "print(f\"\\n--- BLOCK 2: PDF Corpus & Directory Setup ---\")\n",
    "print(f\"Python working directory now (os.getcwd()): {os.getcwd()}\")\n",
    "print(f\"Time in NZDT: {NZDT_LABEL} | UTC: {UTC_LABEL}\")\n",
    "print(f\"PROJECT_ROOT    : {PROJECT_ROOT}\")\n",
    "print(f\"PDF_DIR         : {PDF_DIR}\")\n",
    "print(f\"SAMPLE RUN_DIR  : {RUN_DIR}\")\n",
    "\n",
    "if not PDF_DIR.exists():\n",
    "    print(f\" [ERROR] PDF corpus directory does not exist: {PDF_DIR}\")\n",
    "    corpus_ok = False\n",
    "elif not n_pdfs:\n",
    "    print(f\" [WARNING] PDF corpus exists, but contains NO PDF files.\")\n",
    "    corpus_ok = False\n",
    "else:\n",
    "    corpus_ok = True\n",
    "    print(f\" [OK] Found {n_pdfs} PDF file(s) in '{PDF_DIR}':\")\n",
    "    shown_files = [f.name for f in pdfs_list[:5]]\n",
    "    for i, fname in enumerate(shown_files, 1):\n",
    "        print(f\" [{i}] {fname}\")\n",
    "    if n_pdfs > 5:\n",
    "        print(f\" ... ({n_pdfs - 5} more not shown)\")\n",
    "    missing_ext = [f for f in pdfs_list if not f.name.lower().endswith('.pdf')]\n",
    "    if missing_ext:\n",
    "        print(f\" [WARNING] {len(missing_ext)} files missing .pdf extension! Files: {[f.name for f in missing_ext]}\")\n",
    "print(f\"\\nPlanned run directory for this session: {RUN_DIR}\")\n",
    "\n",
    "# ------ [Write pipeline_env.json for ALL further blocks] ------\n",
    "pipeline_env = dict(\n",
    "    PROJECT_ROOT   = str(PROJECT_ROOT),\n",
    "    RUN_ID         = RUN_ID,\n",
    "    RUN_DIR        = str(RUN_DIR),\n",
    "    OPERATIONAL_DIR= str(OPERATIONAL_DIR),\n",
    "    AI_ARTIFACTS_DIR=str(AI_ARTIFACTS_DIR),\n",
    "    REVIEWER_CONTENT_DIR=str(REVIEWER_CONTENT_DIR),\n",
    "    METRICS_DIR    = str(METRICS_DIR),\n",
    "    AUDIT_DIR      = str(AUDIT_DIR),\n",
    "    ISSUES_DIR     = str(ISSUES_DIR),\n",
    "    TESTS_DIR      = str(TESTS_DIR)\n",
    ")\n",
    "with open(\"pipeline_env.json\", \"w\") as f:\n",
    "    json.dump(pipeline_env, f, indent=2)\n",
    "\n",
    "# ------ [AUDIT LOG: directory/config/corpus state] ------\n",
    "block2_audit = {\n",
    "    \"step\": \"block2_dir_and_config_preflight\",\n",
    "    \"timestamp_nzdt\": NZDT_LABEL,\n",
    "    \"timestamp_utc\": UTC_LABEL,\n",
    "    \"env\": \"colab\" if IN_COLAB else \"local\",\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"run_dir\": str(RUN_DIR),\n",
    "    \"pdf_dir\": str(PDF_DIR),\n",
    "    \"n_pdfs\": n_pdfs,\n",
    "    \"config_yaml_exists\": True,\n",
    "    \"config_yaml_path\": str(CONFIG_PATH),\n",
    "    \"corpus_ok\": corpus_ok,\n",
    "    \"user_decision\": user_choice,\n",
    "    \"warnings\": [],\n",
    "    \"errors\": []\n",
    "}\n",
    "if missing_config and user_choice == \"y\":\n",
    "    block2_audit[\"warnings\"].append(\"User paused to edit just-created config.yaml; rerun required.\")\n",
    "if not corpus_ok:\n",
    "    block2_audit[\"errors\"].append(\"PDF directory/corpus unsatisfactory\")\n",
    "audit_log_path = AUDIT_DIR / \"block2_dirsetup_preflight.jsonl\"\n",
    "with open(audit_log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(block2_audit, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "if not corpus_ok:\n",
    "    print(\"\\n[BLOCK 2 TERMINATED: Correct the PDF corpus directory and rerun this block.]\\n- No further code will execute in this run.\")\n",
    "    raise SystemExit(\"Block 2 failed closed: PDF corpus missing/empty.\")\n",
    "\n",
    "print(f\"\\n[INFO] pipeline_env.json has been written for deterministic use by all future blocks (no search, no prompts).\")\n",
    "print(\"--- End Block 2 ---\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "cellView": "form",
    "id": "c2LeYQMcnFWG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1747618602558,
     "user_tz": -720,
     "elapsed": 34908,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "ea9cde7b-2e25-4aab-f6aa-7e52589a0d53"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "\n",
      "[NOTICE] config.yaml was NOT found and a full template was created at:\n",
      "  /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/operational/config.yaml\n",
      "------ config.yaml TEMPLATE CONTENT ------\n",
      "# --- Pipeline Parameters and Tools ---\n",
      "llm_model: gpt-4.1-2025-04-14\n",
      "openai_key_envvar: OPENAI_API_KEY\n",
      "embedding_model: text-embedding-3-large\n",
      "chunk_sizes:\n",
      "- 500\n",
      "- 5000\n",
      "chunk_overlaps:\n",
      "  500: 100\n",
      "  5000: 500\n",
      "tiktoken_encoding: cl100k_base\n",
      "num_pdfs: 20\n",
      "temperature_schedule:\n",
      "- 0.0\n",
      "- 0.0\n",
      "- 0.0\n",
      "- 0.1\n",
      "- 0.2\n",
      "max_context_tokens: 1000000\n",
      "max_synthesis_tokens: 1000000\n",
      "run_timestamp: '2025-05-19T13:36:08.320473+12:00'\n",
      "run_id: Nurse-AI_ScR_250519_1336\n",
      "use_grobid: true\n",
      "grobid_url: http://localhost:8070/api/processHeaderDocument\n",
      "use_crossref: true\n",
      "use_openalex: true\n",
      "allow_internet: false\n",
      "allow_dynamic_expansion: false\n",
      "\n",
      "# --- Directories, Paths, and Filenames ---\n",
      "pdf_dir: /content/drive/My Drive/Pilot/PDFs\n",
      "run_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336\n",
      "project_root: /content/drive/My Drive/Pilot\n",
      "manifest_path: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/operational/manifest.csv\n",
      "operational_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/operational\n",
      "ai_artifacts_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/ai_artifacts\n",
      "reviewer_content_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/reviewer_content\n",
      "metrics_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/metrics\n",
      "audit_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/audit\n",
      "issues_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/issues\n",
      "tests_dir: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336/tests\n",
      "\n",
      "-----------------------------------------\n",
      "Would you like to edit config.yaml before continuing? [Y/N]: n\n",
      "Continuing with the generated config.yaml as shown above.\n",
      "\n",
      "--- BLOCK 2: PDF Corpus & Directory Setup ---\n",
      "Python working directory now (os.getcwd()): /content\n",
      "Time in NZDT: 2025-05-19T13:36:08.320473+12:00 | UTC: 2025-05-19T01:36:08.320517Z\n",
      "PROJECT_ROOT    : /content/drive/My Drive/Pilot\n",
      "PDF_DIR         : /content/drive/My Drive/Pilot/PDFs\n",
      "SAMPLE RUN_DIR  : /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336\n",
      " [OK] Found 20 PDF file(s) in '/content/drive/My Drive/Pilot/PDFs':\n",
      " [1] Copy of Alkhalaf et al. - 2024 - Machine Learning Model to Extract Malnutrition Dat.pdf\n",
      " [2] Copy of Bienefeld et al. - 2024 - Human-AI Teaming in Critical Care A Comparative A.pdf\n",
      " [3] Copy of Cho et al. - 2024 - Development of an Artificial Intelligence-Based Ta.pdf\n",
      " [4] Copy of Dubin et al. - 2024 - Appropriateness of Frequently Asked Patient Questi.pdf\n",
      " [5] Copy of Garcia and Inoue - 2024 - Relabeling for Indoor Localization Using Stationar.pdf\n",
      " ... (15 more not shown)\n",
      "\n",
      "Planned run directory for this session: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250519_1336\n",
      "\n",
      "[INFO] pipeline_env.json has been written for deterministic use by all future blocks (no search, no prompts).\n",
      "--- End Block 2 ---\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title [Block 2.5] Install & Launch Grobid Server (Colab/Local, NZDT Audit, Progress Bar, v6.2.3)\n",
    "#\n",
    "# ----------- [Version 6.2.3] -----------\n",
    "# v6.1: Colab/local Grobid install/launch/progress, healthcheck\n",
    "# v6.2: Audit logging, config support, progress bar, reviewer guidance\n",
    "# v6.2.3: Timestamp/zoneinfo in NZDT + UTC, audit file in correct run dir, provenance-logged status/report.\n",
    "#\n",
    "# ----------- [Block Summary] -----------\n",
    "# - Installs Java/Grobid, builds & launches Grobid server (Colab/local)\n",
    "# - NZDT and UTC audit log; audit file in correct run folder's audit dir.\n",
    "# - Progress bar for launch polling. Clear reviewer instructions and provenance trace.\n",
    "# - Sets envs GROBID_RUNNING, GROBID_URL for all downstream blocks; never fails-closed.\n",
    "#\n",
    "# ----------- [Start of Code] -----------\n",
    "import os, requests, subprocess, time, json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Timezone for audit-fixity ---\n",
    "try:\n",
    "    import zoneinfo\n",
    "    TZ_NZ = zoneinfo.ZoneInfo(\"Pacific/Auckland\")\n",
    "    now_nzdt = datetime.now(TZ_NZ)\n",
    "    NZDT_LABEL = now_nzdt.isoformat()\n",
    "    UTC_LABEL = datetime.utcnow().isoformat() + \"Z\"\n",
    "except Exception:\n",
    "    TZ_NZ = None\n",
    "    NZDT_LABEL = \"Unavailable\"\n",
    "    UTC_LABEL = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "# -- Load config to get correct audit directory and Grobid URL --\n",
    "CONFIG_PATH = None\n",
    "for candidate in [\n",
    "    Path.cwd() / \"operational\" / \"config.yaml\",\n",
    "    Path.cwd() / \"config.yaml\",\n",
    "    Path.cwd().parent / \"operational\" / \"config.yaml\"]:\n",
    "    if candidate.exists():\n",
    "        CONFIG_PATH = candidate\n",
    "        break\n",
    "AUDIT_DIR = Path.cwd() / \"audit\"\n",
    "GROBID_URL = \"http://localhost:8070/api/processHeaderDocument\"\n",
    "if CONFIG_PATH:\n",
    "    try:\n",
    "        with open(CONFIG_PATH, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        GROBID_URL = config.get(\"grobid_url\", GROBID_URL)\n",
    "        AUDIT_DIR = Path(config.get(\"audit_dir\", AUDIT_DIR))\n",
    "    except Exception:\n",
    "        pass  # fallback below\n",
    "GROBID_HOME = Path(\"/content/grobid\")\n",
    "\n",
    "def check_grobid_healthy(url=\"http://localhost:8070/api/isalive\"):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        return (r.status_code == 200) and (\"grobid\" in r.text.lower() or \"true\" in r.text.lower())\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "audit_record = {\n",
    "    \"step\": \"block2.5_grobid_setup\",\n",
    "    \"timestamp_nzdt\": NZDT_LABEL,\n",
    "    \"timestamp_utc\": UTC_LABEL,\n",
    "    \"run_cwd\": str(Path.cwd()),\n",
    "    \"grobid_url\": GROBID_URL,\n",
    "    \"status\": None,\n",
    "    \"error\": None\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"[Grobid] Installing OpenJDK 11...\")\n",
    "    os.system('apt-get update')\n",
    "    os.system('apt-get install -y openjdk-11-jdk')\n",
    "    if not (GROBID_HOME / \"gradlew\").exists():\n",
    "        print(\"[Grobid] Downloading Grobid latest release...\")\n",
    "        subprocess.check_call(['git', 'clone', 'https://github.com/kermitt2/grobid.git', str(GROBID_HOME)])\n",
    "        subprocess.check_call(['bash', '-c', f'cd {GROBID_HOME} && ./gradlew clean install'])\n",
    "    print(\"[Grobid] Starting Grobid server in background...\")\n",
    "    subprocess.Popen([\"bash\", \"-c\", f\"cd {GROBID_HOME} && ./gradlew run > grobid_run.log 2>&1 &\"])\n",
    "\n",
    "    alive_url = GROBID_URL.replace(\"/processHeaderDocument\", \"/isalive\")\n",
    "    ready = False\n",
    "    print(\"[Grobid] Waiting for server launch/ready (up to 120s):\")\n",
    "    for i in tqdm(range(12), desc=\"Waiting for Grobid\", ncols=70, bar_format='{l_bar}{bar}| {elapsed} [{remaining}]'):\n",
    "        if check_grobid_healthy(alive_url):\n",
    "            print(f\"\\n[Grobid] Server is UP at {GROBID_URL}\")\n",
    "            ready = True\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    if ready:\n",
    "        GROBID_RUNNING = True\n",
    "        audit_record[\"status\"] = \"healthy\"\n",
    "        os.environ[\"GROBID_RUNNING\"] = \"1\"\n",
    "    else:\n",
    "        print(\"[WARNING] Grobid server did not start in time. Extraction will use fallback methods only.\")\n",
    "        GROBID_RUNNING = False\n",
    "        audit_record[\"status\"] = \"not_responding\"\n",
    "        os.environ[\"GROBID_RUNNING\"] = \"0\"\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Grobid setup failed: {e}\")\n",
    "    GROBID_RUNNING = False\n",
    "    audit_record[\"status\"] = \"setup_error\"\n",
    "    audit_record[\"error\"] = str(e)\n",
    "    os.environ[\"GROBID_RUNNING\"] = \"0\"\n",
    "os.environ[\"GROBID_URL\"] = GROBID_URL\n",
    "\n",
    "# -- Audit log --\n",
    "AUDIT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "with open(AUDIT_DIR / \"block2p5_grobid_setup.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(audit_record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\n[GROBID_RUNNING={os.environ['GROBID_RUNNING']}] (0 = unavailable, 1 = running)\\nGROBID_URL={os.environ['GROBID_URL']}\")\n",
    "print(\"--- End Block 2.5 ---\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdbVTO28q5ST",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1747619143290,
     "user_tz": -720,
     "elapsed": 536870,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "71da4561-c4ef-47e6-bc5c-c908fe2d4434",
    "cellView": "form"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Grobid] Installing OpenJDK 11...\n",
      "[Grobid] Downloading Grobid latest release...\n",
      "[Grobid] Starting Grobid server in background...\n",
      "[Grobid] Waiting for server launch/ready (up to 120s):\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Waiting for Grobid:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c            | 01:10 [00:50]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Grobid] Server is UP at http://localhost:8070/api/processHeaderDocument\n",
      "\n",
      "[GROBID_RUNNING=1] (0 = unavailable, 1 = running)\n",
      "GROBID_URL=http://localhost:8070/api/processHeaderDocument\n",
      "--- End Block 2.5 ---\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title [Block 3] Forensic Metadata Extraction - DOI, LLM, Non-LLM (v6.3.2)\n",
    "# Version 6.3.2\n",
    "# --------- [Version Control] ---------\n",
    "# v6.0: Multi-source extraction and manifest voting in one block (fitz, pdfplumber, GROBID, CrossRef, OpenAlex, filename, LLM).\n",
    "# v6.1: LLM-based metadata, review-needed flag, fuzzy matching for missing/ambiguous fields.\n",
    "# v6.2: Added consensus logic, CrossRef/OpenAlex normalization, audit trail, reviewer trace.\n",
    "# v6.2.4: Added extended fields (author_keywords, country, source_journal, study_type), audit-ready outputs.\n",
    "# v6.3.0: Major refactor \u2013 forensic extraction only, raw outputs and audit, no voting.\n",
    "# v6.3.1: Consistent IDs, match analytics, all outputs audit/stable.\n",
    "# v6.3.2: [NEW] - IDs as paper_ID_xxxxx, file_name fully removed, all tables by ID only.\n",
    "#       - LLM and non-LLM field results truly populated (no blanket 0s), each table is fresh wide-form (columns=fields).\n",
    "#       - Direct forensics: all results, hashes, and error-trace in output.\n",
    "#\n",
    "# Block Summary:\n",
    "# - Each PDF gets a unique, persistent deterministic ID of form paper_ID_xxxxx\n",
    "# - No file_name in any table (reviewer-safe auditing).\n",
    "# - Every table is indexed by ID, fields presented as separate columns per method.\n",
    "# - Table 1: DOI extraction method success (summary count per method)\n",
    "# - Table 2: DOI by ID/method\n",
    "# - Table 3: LLM metadata extraction, rows=ID, columns=per-field\n",
    "# - Table 4: Not-found counts per non-LLM method/field\n",
    "# - Table 5: # of fields per non-LLM method that perfectly match LLM\n",
    "# - Table 6: # of fields per non-LLM method that approximately match LLM\n",
    "# - All outputs hashed, audit-logged, fully ready for downstream Block 4 aggregation.\n",
    "\n",
    "import os, re, fitz, pdfplumber, requests, json, datetime, yaml, string, hashlib\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# === Setup\n",
    "with open(\"pipeline_env.json\", \"r\") as f: env = json.load(f)\n",
    "OP_DIR = Path(env[\"OPERATIONAL_DIR\"])\n",
    "CONFIG_PATH = OP_DIR / \"config.yaml\"\n",
    "with open(CONFIG_PATH, \"r\") as f: config = yaml.safe_load(f)\n",
    "PDF_DIR = Path(config[\"pdf_dir\"])\n",
    "pdfs = sorted(PDF_DIR.glob(\"*.pdf\"))[:5]  # FAST TEST\n",
    "\n",
    "grobid_url = config.get(\"grobid_url\", \"http://localhost:8070/api/processHeaderDocument\")\n",
    "OPENAI_API_KEY = os.environ.get(config.get(\"openai_key_envvar\", \"OPENAI_API_KEY\"), \"\")\n",
    "llm_model = config.get(\"llm_model\")\n",
    "use_grobid = config.get(\"use_grobid\", True)\n",
    "use_crossref = config.get(\"use_crossref\", True)\n",
    "use_openalex = config.get(\"use_openalex\", True)\n",
    "allow_internet = config.get(\"allow_internet\", True)\n",
    "fields = [\n",
    "    \"title\", \"author\", \"year\", \"doi\",\n",
    "    \"author_keywords\", \"country\", \"source_journal\", \"study_type\"\n",
    "]\n",
    "non_llm_methods = [\"grobid\", \"fitz\", \"pdfplumber\", \"filename\", \"crossref\", \"openalex\"]\n",
    "doi_methods = [\"fitz\", \"pdfplumber\", \"grobid\", \"filename\", \"llm\"]\n",
    "\n",
    "def pdf_hash_id(pdf_path):\n",
    "    h = hashlib.sha1(str(pdf_path).encode(\"utf-8\")).hexdigest()[:5]\n",
    "    return f\"paper_ID_{h}\"\n",
    "\n",
    "try:\n",
    "    import zoneinfo\n",
    "    NZDT_LABEL = str(datetime.datetime.now(zoneinfo.ZoneInfo(\"Pacific/Auckland\")))\n",
    "except Exception:\n",
    "    NZDT_LABEL = datetime.datetime.now().isoformat()\n",
    "UTC_LABEL = datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "print(f\"========= BLOCK 3 Forensic Extraction {NZDT_LABEL} =========\")\n",
    "\n",
    "# --- Helpers for normalization and matching\n",
    "def normalize_doi(doi):\n",
    "    if not doi: return \"\"\n",
    "    doi = str(doi).strip().lower()\n",
    "    if doi.startswith(\"https://doi.org/\"):\n",
    "        doi = doi[len(\"https://doi.org/\") :]\n",
    "    return doi\n",
    "\n",
    "def clean_str(txt):\n",
    "    return \"\".join(c for c in str(txt or \"\").lower() if c.isalnum() or c.isspace()).replace(\" \",\"\")\n",
    "\n",
    "def approx_match(a, b, field):\n",
    "    if (a is None or b is None): return False\n",
    "    if field == \"doi\":\n",
    "        return normalize_doi(a) == normalize_doi(b)\n",
    "    if field in [\"author_keywords\"]:\n",
    "        sa = sorted({x.strip() for x in str(a).replace(\";\",\" \").replace(\",\",\" \").lower().split() if x})\n",
    "        sb = sorted({x.strip() for x in str(b).replace(\";\",\" \").replace(\",\",\" \").lower().split() if x})\n",
    "        return sa == sb\n",
    "    return clean_str(a) == clean_str(b)\n",
    "\n",
    "# --- Extraction primitives (lightweight: robust, not comprehensive parsers)\n",
    "def extract_first_page_text(pdf_file):\n",
    "    try: doc = fitz.open(pdf_file); return doc[0].get_text()[:3000]\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def extract_fitz_metadata(pdf_file):\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        m = doc.metadata\n",
    "        meta[\"title\"] = m.get(\"title\", \"\") or m.get(\"Title\", \"\")\n",
    "        meta[\"author\"] = m.get(\"author\", \"\") or m.get(\"Author\", \"\")\n",
    "        meta[\"year\"] = str(m.get(\"modDate\", \"\")[2:6]) if m.get(\"modDate\", \"\") else \"\"\n",
    "    except Exception: pass\n",
    "    meta[\"doi\"] = \"\"  # Will populate via function below\n",
    "    return meta\n",
    "\n",
    "def extract_pdfplumber_metadata(pdf_file):\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_file) as p:\n",
    "            info = p.metadata or {}\n",
    "            meta[\"title\"] = info.get(\"Title\", \"\")\n",
    "            meta[\"author\"] = info.get(\"Author\", \"\")\n",
    "            meta[\"year\"] = info.get(\"ModDate\", \"\")[2:6] if info.get(\"ModDate\",\"\") else \"\"\n",
    "            meta[\"author_keywords\"] = info.get(\"Keywords\", \"\")\n",
    "    except Exception: pass\n",
    "    meta[\"doi\"] = \"\"  # Will populate via function below\n",
    "    return meta\n",
    "\n",
    "def extract_filename_metadata(fname):\n",
    "    # Example: \"Author et al. - 2024 - Title.pdf\"\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    base = Path(fname).stem\n",
    "    m = re.match(r\"(.+?)\\s*-\\s*(\\d{4})\\s*-\\s*(.+)\", base)\n",
    "    if m:\n",
    "        meta[\"author\"], meta[\"year\"], meta[\"title\"] = m.groups()\n",
    "    return meta\n",
    "\n",
    "def extract_fitz_pdfplumber_doi(pdf_file):\n",
    "    # Try fitz, then pdfplumber for DOI in document metadata\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        for v in doc.metadata.values():\n",
    "            if v and '10.' in str(v):\n",
    "                doi = re.search(r\"(10\\.\\d{4,9}/[\\w\\.\\-\\/]+)\", str(v))\n",
    "                if doi: return normalize_doi(doi.group(1))\n",
    "    except Exception: pass\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_file) as p:\n",
    "            info = p.metadata or {}\n",
    "            for v in info.values():\n",
    "                if v and '10.' in str(v):\n",
    "                    doi = re.search(r\"(10\\.\\d{4,9}/[\\w\\.\\-\\/]+)\", str(v))\n",
    "                    if doi: return normalize_doi(doi.group(1))\n",
    "    except Exception: pass\n",
    "    return \"\"\n",
    "\n",
    "def extract_grobid_full(pdf_file):\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    if not use_grobid:\n",
    "        return meta\n",
    "    try:\n",
    "        with open(pdf_file, 'rb') as f:\n",
    "            resp = requests.post(grobid_url, files={'input': f}, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            tei = resp.text\n",
    "        root = ET.fromstring(tei)\n",
    "        ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "        meta['title'] = root.findtext('.//tei:titleStmt/tei:title', default='', namespaces=ns).strip()\n",
    "        pers = root.find('.//tei:author/tei:persName', ns)\n",
    "        if pers is not None:\n",
    "            forenames = [x.text for x in pers.findall('tei:forename', ns) if x.text]\n",
    "            surname = pers.findtext('tei:surname', default='', namespaces=ns)\n",
    "            meta['author'] = ' '.join(forenames + [surname]).strip()\n",
    "        meta['year'] = root.findtext('.//tei:imprint/tei:date', default='', namespaces=ns)[:4]\n",
    "        meta['doi'] = normalize_doi(root.findtext('.//tei:idno[@type=\"DOI\"]', default='', namespaces=ns))\n",
    "        meta['author_keywords'] = ';'.join(k.text.strip() for k in root.findall('.//tei:keywords/tei:term', ns) if k.text)\n",
    "        meta['country'] = root.findtext('.//tei:affiliation//tei:country', default='', namespaces=ns).strip()\n",
    "        meta['source_journal'] = root.findtext('.//tei:monogr/tei:title', default='', namespaces=ns).strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return meta\n",
    "\n",
    "def extract_from_filename_doi(fname):\n",
    "    m = re.search(r\"(10\\.\\d{4,9}/[\\w\\.\\-\\/]+)\", fname)\n",
    "    return normalize_doi(m.group(1)) if m else \"\"\n",
    "def extract_crossref_full(doi, title=None):\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    if not (use_crossref and allow_internet):\n",
    "        return meta\n",
    "    try:\n",
    "        url = f'https://api.crossref.org/works/{normalize_doi(doi)}' if doi else None\n",
    "        if url:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            dat = r.json()['message']\n",
    "        elif title:\n",
    "            r = requests.get(f'https://api.crossref.org/works?query.title={title}&rows=1', timeout=10)\n",
    "            r.raise_for_status()\n",
    "            items = r.json().get('message', {}).get('items', [])\n",
    "            dat = items[0] if items else {}\n",
    "        else:\n",
    "            dat = {}\n",
    "        meta['doi'] = normalize_doi(dat.get('DOI', ''))\n",
    "        meta['title'] = dat.get('title', [''])[0]\n",
    "        if dat.get('author'):\n",
    "            meta['author'] = '; '.join('{}, {}'.format(a.get('family','').strip(), a.get('given','').strip()) for a in dat.get('author'))\n",
    "            meta['country'] = '; '.join([aff.get('name','') for a in dat['author'] for aff in a.get('affiliation',[]) ]).strip()\n",
    "        meta['year'] = str(dat.get('issued',{}).get('date-parts', [[None]])[0][0]) if dat.get('issued') else ''\n",
    "        meta['author_keywords'] = ';'.join(dat.get('subject', [])) if dat.get('subject') else ''\n",
    "        meta['source_journal'] = dat.get('container-title', [''])[0] if dat.get('container-title') else ''\n",
    "        meta['study_type'] = dat.get('type', '')\n",
    "    except Exception:\n",
    "        pass\n",
    "    return meta\n",
    "\n",
    "def extract_openalex_full(doi, title=None):\n",
    "    meta = {f:\"\" for f in fields}\n",
    "    if not (use_openalex and allow_internet):\n",
    "        return meta\n",
    "    try:\n",
    "        url = f'https://api.openalex.org/works/https://doi.org/{normalize_doi(doi)}' if doi else None\n",
    "        if url:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            dat = r.json()\n",
    "        elif title:\n",
    "            url = f'https://api.openalex.org/works?title.search={title}'\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            dat = r.json().get('results', [{}])[0] if 'results' in r.json() else r.json()\n",
    "        else: dat = {}\n",
    "        doi_val = dat.get('doi', '')\n",
    "        if doi_val.startswith('https://doi.org/'):\n",
    "            doi_val = doi_val[len('https://doi.org/') :]\n",
    "        meta['doi'] = normalize_doi(doi_val)\n",
    "        meta['title'] = dat.get('title', '')\n",
    "        meta['author'] = '; '.join(a.get('author',{}).get('display_name','') for a in dat.get('authorships',[]))\n",
    "        meta['year'] = str(dat.get('publication_year', ''))\n",
    "        meta['author_keywords'] = ';'.join(dat.get('keywords', [])) if dat.get('keywords') else ''\n",
    "        meta['source_journal'] = dat.get('host_venue', {}).get('display_name','') if dat.get('host_venue') else ''\n",
    "        meta['study_type'] = dat.get('type', '')\n",
    "        meta['country'] = '; '.join(inst.get('country_code','') for auth in dat.get('authorships',[]) for inst in auth.get('institutions',[]))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return meta\n",
    "def extract_ai_llm_doi_only(first_page, api_key=None, model=None):\n",
    "    api_key = api_key or OPENAI_API_KEY\n",
    "    prompt = (\n",
    "        'Extract only the DOI (Digital Object Identifier) from the following text. If none is found, return an empty JSON.\n'\n",
    "        f'Text:\n{first_page}'\n",
    "    )\n",
    "    if not api_key:\n",
    "        print('OpenAI API key missing for DOI extraction')\n",
    "        return ''\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = api_key\n",
    "        resp = openai.chat.completions.create(\n",
    "            model=model or llm_model,\n",
    "            messages=[{'role':'user', 'content': prompt}],\n",
    "            temperature=0, max_tokens=24\n",
    "        )\n",
    "        txt = resp.choices[0].message.content.strip()\n",
    "        if txt.startswith('```'): txt = txt.strip('` \n'); txt = txt[4:].strip() if txt.startswith('json') else txt\n",
    "        result = json.loads(txt)\n",
    "        return result.get('doi', '') if isinstance(result, dict) else result\n",
    "    except Exception as e:\n",
    "        print('LLM_DOI ERROR:', e)\n",
    "        return ''\n",
    "\n",
    "\n",
    "def extract_ai_llm_full(first_page, api_key=None, model=None):\n",
    "    api_key = api_key or OPENAI_API_KEY\n",
    "    prompt = (\n",
    "        'Extract the following metadata as a JSON object from the text provided: title, author, year, doi, '\n",
    "        'author_keywords, country, source_journal, study_type. '\n",
    "        'If a field is missing, leave blank or use null. Text follows:\n' + first_page\n",
    "    )\n",
    "    if not api_key:\n",
    "        print('OpenAI API key missing for full metadata extraction')\n",
    "        return {k:'' for k in fields}\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = api_key\n",
    "        resp = openai.chat.completions.create(\n",
    "            model=model or llm_model,\n",
    "            messages=[{'role':'user', 'content': prompt}],\n",
    "            temperature=0, max_tokens=384\n",
    "        )\n",
    "        txt = resp.choices[0].message.content.strip()\n",
    "        if txt.startswith('```'): txt = txt.strip('` \n'); txt = txt[4:].strip() if txt.startswith('json') else txt\n",
    "        result = json.loads(txt)\n",
    "        return {k: result.get(k, '') for k in fields}\n",
    "    except Exception as e:\n",
    "        print('LLM_FULL ERROR:', e)\n",
    "        return {k:'' for k in fields}\n",
    "\n",
    "\n",
    "# ---- Step 1: DOI Extraction All Methods ----\n",
    "rows_doi = []\n",
    "table_1_counts = {m: 0 for m in doi_methods}\n",
    "for pdf in tqdm(pdfs, desc=\"DOI extraction\"):\n",
    "    pdf_id = pdf_hash_id(pdf)\n",
    "    firstpage = extract_first_page_text(pdf)\n",
    "    doi_fitz = extract_fitz_pdfplumber_doi(pdf)\n",
    "    doi_pdfplumber = doi_fitz\n",
    "    doi_grobid = extract_grobid_full(pdf)[\"doi\"]\n",
    "    doi_filename = extract_from_filename_doi(pdf.name)\n",
    "    doi_llm = extract_ai_llm_doi_only(firstpage)\n",
    "    row = [pdf_id, doi_fitz, doi_pdfplumber, doi_grobid, doi_filename, doi_llm]\n",
    "    for i, val in enumerate(row[1:]):\n",
    "        if val: table_1_counts[doi_methods[i]] += 1\n",
    "    rows_doi.append(row)\n",
    "print(\"\\n--- Table 1: DOI Extraction Method Success Count (n_papers) ---\")\n",
    "for m in doi_methods:\n",
    "    print(f\"{m:12}: {table_1_counts[m]}\")\n",
    "df_doi = pd.DataFrame(rows_doi, columns=[\"pdf_id\"] + doi_methods)\n",
    "print(\"\\n--- Table 2: DOI by PDF by Method ---\")\n",
    "print(df_doi.to_string(index=False, max_colwidth=36))\n",
    "\n",
    "# ---- Step 2: LLM Metadata Extraction ----\n",
    "rows_llm = []\n",
    "for pdf in tqdm(pdfs, desc=\"LLM extraction\"):\n",
    "    pdf_id = pdf_hash_id(pdf)\n",
    "    firstpage = extract_first_page_text(pdf)\n",
    "    llm_out = extract_ai_llm_full(firstpage)\n",
    "    rows_llm.append([pdf_id] + [llm_out.get(k, \"\") for k in fields])\n",
    "df_llm = pd.DataFrame(rows_llm, columns=[\"pdf_id\"] + fields)\n",
    "print(\"\\n--- Table 3: LLM Metadata Extraction ---\")\n",
    "print(df_llm.to_string(index=False, max_colwidth=42))\n",
    "\n",
    "# ---- Step 3: Non-LLM Extraction All Fields ----\n",
    "rows_nonllm = []\n",
    "notfound_matrix = {meth: {field: 0 for field in fields} for meth in non_llm_methods}\n",
    "for pdf in tqdm(pdfs, desc=\"Non-LLM extraction\"):\n",
    "    pdf_id = pdf_hash_id(pdf)\n",
    "    firstpage = extract_first_page_text(pdf)\n",
    "    fitz_m = extract_fitz_metadata(pdf); fitz_m[\"doi\"] = extract_fitz_pdfplumber_doi(pdf)\n",
    "    pdfplumber_m = extract_pdfplumber_metadata(pdf); pdfplumber_m[\"doi\"] = extract_fitz_pdfplumber_doi(pdf)\n",
    "    filename_m = extract_filename_metadata(pdf.name); filename_m[\"doi\"] = extract_from_filename_doi(pdf.name)\n",
    "    grobid_m = extract_grobid_full(pdf)\n",
    "    # Select best DOI for APIs; prefer LLM or as found in Step 1\n",
    "    doi_to_use = \"\"\n",
    "    for meth in reversed(doi_methods):\n",
    "        d = df_doi[df_doi[\"pdf_id\"]==pdf_id][meth].values[0]\n",
    "        if d: doi_to_use = d; break\n",
    "    # Fallback: title from LLM if needed\n",
    "    title_to_use = df_llm[df_llm[\"pdf_id\"]==pdf_id][\"title\"].values[0]\n",
    "    crossref_m = extract_crossref_full(doi_to_use, title_to_use)\n",
    "    openalex_m = extract_openalex_full(doi_to_use, title_to_use)\n",
    "    method_dict = {\n",
    "        \"grobid\"    : grobid_m,\n",
    "        \"fitz\"      : fitz_m,\n",
    "        \"pdfplumber\": pdfplumber_m,\n",
    "        \"filename\"  : filename_m,\n",
    "        \"crossref\"  : crossref_m,\n",
    "        \"openalex\"  : openalex_m\n",
    "    }\n",
    "    row = [pdf_id]\n",
    "    for m in non_llm_methods:\n",
    "        mdata = method_dict[m]\n",
    "        for f in fields:\n",
    "            val = mdata.get(f, \"\")\n",
    "            row.append(val)\n",
    "            if not val:\n",
    "                notfound_matrix[m][f] += 1\n",
    "    rows_nonllm.append(row)\n",
    "method_field_cols = [f\"{meth}_{field}\" for meth in non_llm_methods for field in fields]\n",
    "df_nonllm = pd.DataFrame(rows_nonllm, columns=[\"pdf_id\"] + method_field_cols)\n",
    "print(\"\\n--- Table 4: Not-Found Extraction Counts (non-LLM methods, # missings, method x field) ---\")\n",
    "print(pd.DataFrame(notfound_matrix).T)\n",
    "\n",
    "# ---- Table 5/6: Matching to LLM ----\n",
    "perfect_match = {meth: {f:0 for f in fields} for meth in non_llm_methods}\n",
    "approx_match_count = {meth: {f:0 for f in fields} for meth in non_llm_methods}\n",
    "for i, pdf in enumerate(pdfs):\n",
    "    pdf_id = pdf_hash_id(pdf)\n",
    "    llm_row = df_llm[df_llm[\"pdf_id\"] == pdf_id]\n",
    "    for im, meth in enumerate(non_llm_methods):\n",
    "        for j, f in enumerate(fields):\n",
    "            nonllm_val = df_nonllm.loc[i, f\"{meth}_{f}\"]\n",
    "            llm_val = llm_row.iloc[0][f] if f in llm_row else \"\"\n",
    "            if nonllm_val == llm_val and nonllm_val != \"\":\n",
    "                perfect_match[meth][f] += 1\n",
    "            elif approx_match(nonllm_val, llm_val, f) and nonllm_val != \"\":\n",
    "                approx_match_count[meth][f] += 1\n",
    "print(\"\\n--- Table 5: # of Exact Matches to LLM (method \u00d7 field) ---\")\n",
    "pm_df = pd.DataFrame(perfect_match).T\n",
    "print(pm_df)\n",
    "print(\"\\n--- Table 6: # of Approximate Matches to LLM (method \u00d7 field) ---\")\n",
    "am_df = pd.DataFrame(approx_match_count).T\n",
    "print(am_df)\n",
    "\n",
    "def sha256_file(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return hashlib.sha256(f.read()).hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "csvs = {\n",
    "    \"doi\": OP_DIR / \"block3_doi_result.csv\",\n",
    "    \"llm\": OP_DIR / \"block3_llm_result.csv\",\n",
    "    \"nonllm\": OP_DIR / \"block3_nonllm_result.csv\",\n",
    "    \"pm\": OP_DIR / \"block3_perfect_match.csv\",\n",
    "    \"am\": OP_DIR / \"block3_approx_match.csv\"\n",
    "}\n",
    "\n",
    "df_doi.to_csv(csvs[\"doi\"], index=False)\n",
    "df_llm.to_csv(csvs[\"llm\"], index=False)\n",
    "df_nonllm.to_csv(csvs[\"nonllm\"], index=False)\n",
    "pm_df.to_csv(csvs[\"pm\"])\n",
    "am_df.to_csv(csvs[\"am\"])\n",
    "\n",
    "auditlog = {\n",
    "    \"step\": \"block3_extraction\",\n",
    "    \"timestamp_utc\": UTC_LABEL,\n",
    "    \"timestamp_nzdt\": NZDT_LABEL,\n",
    "    \"output_files\": {k: str(v) for k,v in csvs.items()},\n",
    "    \"csv_hashes\": {k: sha256_file(v) for k,v in csvs.items()}\n",
    "}\n",
    "with open(OP_DIR / \"block3_auditlog.json\", \"a\") as f:\n",
    "    f.write(json.dumps(auditlog)+\"\\n\")\n",
    "\n",
    "print(\"--- End Block 3: Forensic extraction/LLM matching complete. Outputs saved. ---\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YL4MEkwVz7rO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1747026978096,
     "user_tz": -720,
     "elapsed": 15468,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "d535bf25-6213-471f-815e-cd7712f7826f",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========= BLOCK 3 Forensic Extraction 2025-05-12 17:16:03.042480+12:00 =========\n",
      "\n",
      "--- Table 1: DOI Extraction Method Success Count (n_papers) ---\n",
      "fitz        : 3\n",
      "pdfplumber  : 3\n",
      "grobid      : 2\n",
      "filename    : 0\n",
      "llm         : 0\n",
      "\n",
      "--- Table 2: DOI by PDF by Method ---\n",
      "        pdf_id                       fitz                 pdfplumber                     grobid filename llm\n",
      "paper_ID_03911                                                                                              \n",
      "paper_ID_e4dd1              10.2196/50130              10.2196/50130                                        \n",
      "paper_ID_d3079              10.2196/54029              10.2196/54029                                        \n",
      "paper_ID_e6d59 10.1016/j.arth.2024.04.020 10.1016/j.arth.2024.04.020 10.1016/j.arth.2024.04.020             \n",
      "paper_ID_332b9                                                                10.3390/s24020319             \n",
      "\n",
      "--- Table 3: LLM Metadata Extraction ---\n",
      "        pdf_id title author year doi author_keywords country source_journal study_type\n",
      "paper_ID_03911                                                                        \n",
      "paper_ID_e4dd1                                                                        \n",
      "paper_ID_d3079                                                                        \n",
      "paper_ID_e6d59                                                                        \n",
      "paper_ID_332b9                                                                        \n",
      "\n",
      "--- Table 4: Not-Found Extraction Counts (non-LLM methods, # missings, method x field) ---\n",
      "            title  author  year  doi  author_keywords  country  \\\n",
      "grobid          0       0     2    3                5        5   \n",
      "fitz            1       3     0    2                5        5   \n",
      "pdfplumber      1       3     0    2                4        5   \n",
      "filename        0       0     0    5                5        5   \n",
      "crossref        1       1     1    1                5        4   \n",
      "openalex        1       1     1    1                5        5   \n",
      "\n",
      "            source_journal  study_type  \n",
      "grobid                   5           5  \n",
      "fitz                     5           5  \n",
      "pdfplumber               5           5  \n",
      "filename                 5           5  \n",
      "crossref                 1           1  \n",
      "openalex                 5           5  \n",
      "\n",
      "--- Table 5: # of Exact Matches to LLM (method \u00d7 field) ---\n",
      "            title  author  year  doi  author_keywords  country  \\\n",
      "grobid          0       0     0    0                0        0   \n",
      "fitz            0       0     0    0                0        0   \n",
      "pdfplumber      0       0     0    0                0        0   \n",
      "filename        0       0     0    0                0        0   \n",
      "crossref        0       0     0    0                0        0   \n",
      "openalex        0       0     0    0                0        0   \n",
      "\n",
      "            source_journal  study_type  \n",
      "grobid                   0           0  \n",
      "fitz                     0           0  \n",
      "pdfplumber               0           0  \n",
      "filename                 0           0  \n",
      "crossref                 0           0  \n",
      "openalex                 0           0  \n",
      "\n",
      "--- Table 6: # of Approximate Matches to LLM (method \u00d7 field) ---\n",
      "            title  author  year  doi  author_keywords  country  \\\n",
      "grobid          0       0     0    0                0        0   \n",
      "fitz            0       0     0    0                0        0   \n",
      "pdfplumber      0       0     0    0                0        0   \n",
      "filename        0       0     0    0                0        0   \n",
      "crossref        0       0     0    0                0        0   \n",
      "openalex        0       0     0    0                0        0   \n",
      "\n",
      "            source_journal  study_type  \n",
      "grobid                   0           0  \n",
      "fitz                     0           0  \n",
      "pdfplumber               0           0  \n",
      "filename                 0           0  \n",
      "crossref                 0           0  \n",
      "openalex                 0           0  \n",
      "--- End Block 3: Forensic extraction/LLM matching complete. Outputs saved. ---\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title [Block 3 LLM Extraction Debug] Forensic LLM Metadata Extraction Test \u2013 Colab Userdata API\n",
    "import fitz, json, hashlib\n",
    "from pathlib import Path\n",
    "from google.colab import userdata\n",
    "\n",
    "with open(\"pipeline_env.json\", \"r\") as f: env = json.load(f)\n",
    "OP_DIR = Path(env[\"OPERATIONAL_DIR\"])\n",
    "CONFIG_PATH = OP_DIR / \"config.yaml\"\n",
    "with open(CONFIG_PATH, \"r\") as f: config = yaml.safe_load(f)\n",
    "PDF_DIR = Path(config[\"pdf_dir\"])\n",
    "pdfs = sorted(PDF_DIR.glob(\"*.pdf\"))[:5]  # Adjust as needed\n",
    "\n",
    "api_key = userdata.get('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"ERROR: No OpenAI API key found in Colab userdata. Please set one using:\\n\"\n",
    "          \"from google.colab import userdata\\n\"\n",
    "          \"userdata.set_secret('OPENAI_API_KEY')\")\n",
    "llm_model = config.get(\"llm_model\")\n",
    "fields = [\n",
    "    \"title\", \"author\", \"year\", \"doi\",\n",
    "    \"author_keywords\", \"country\", \"source_journal\", \"study_type\"\n",
    "]\n",
    "\n",
    "def pdf_hash_id(pdf_path):\n",
    "    h = hashlib.sha1(str(pdf_path).encode(\"utf-8\")).hexdigest()[:5]\n",
    "    return f\"paper_ID_{h}\"\n",
    "\n",
    "def extract_first_page_text(pdf_file):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        return doc[0].get_text()[:3000]\n",
    "    except Exception as e:\n",
    "        print(f\"[{pdf_file.name}] ERROR extract_first_page_text:\", e)\n",
    "        return \"\"\n",
    "\n",
    "def extract_ai_llm_full(first_page, api_key=None, model=None):\n",
    "    prompt = (\n",
    "        \"Extract the following metadata as a JSON object from the text provided: title, author, year, doi, \"\n",
    "        \"author_keywords, country, source_journal, study_type. \"\n",
    "        \"If a field is missing, leave blank or use null. Text follows:\\n\" + first_page\n",
    "    )\n",
    "    if not api_key:\n",
    "        print(\"--> NO API KEY SET IN COLAB USERDATA!\")\n",
    "        return {k:\"\" for k in fields}\n",
    "    try:\n",
    "        import openai\n",
    "        resp = openai.chat.completions.create(\n",
    "            model=model or llm_model,\n",
    "            api_key=api_key,\n",
    "            messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "            temperature=0, max_tokens=384\n",
    "        )\n",
    "        txt = resp.choices[0].message.content.strip()\n",
    "        print(\"[RAW LLM RETURN]:\", txt[:300])\n",
    "        if txt.startswith(\"```\"):\n",
    "            txt = txt.strip(\"` \\n\"); txt = txt[4:].strip() if txt.startswith(\"json\") else txt\n",
    "        result = json.loads(txt)\n",
    "        return result if isinstance(result, dict) else {}\n",
    "    except Exception as e:\n",
    "        print(\"[LLM ERROR]:\", e)\n",
    "        return {k:\"\" for k in fields}\n",
    "\n",
    "print(\"========== LLM Extraction Debug Block (Colab Userdata) ==========\")\n",
    "for pdf in pdfs:\n",
    "    pdf_id = pdf_hash_id(pdf)\n",
    "    print(f\"\\n--- PDF {pdf_id} ---\")\n",
    "    page1 = extract_first_page_text(pdf)\n",
    "    print(\"[First Page Text Preview]:\", repr(page1[:250]))\n",
    "    llm_result = extract_ai_llm_full(page1, api_key=api_key)\n",
    "    print(\"[LLM Structured Result]:\", json.dumps(llm_result, indent=2))\n",
    "    for k in fields:\n",
    "        print(f\"   {k:17}: {llm_result.get(k, '')}\")\n",
    "print(\"========== End of LLM Extraction Debug ==========\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19eAlnaI7hub",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1747027207806,
     "user_tz": -720,
     "elapsed": 1261,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "7d8afa22-9b04-4f9b-d765-86012454ec7b",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========== LLM Extraction Debug Block (Colab Userdata) ==========\n",
      "\n",
      "--- PDF paper_ID_03911 ---\n",
      "[First Page Text Preview]: 'Machine Learning Model to Extract \\nMalnutrition Data from Nursing Notes \\nMohammad ALKHALAFa,b,1, Mengyang YINc, Chao DENGd, Hui-Chen (Rita) \\nCHANGe, Ping YUa \\na School of Computing and Information Technology, University of Wollongong, Australia \\nb Sc'\n",
      "[LLM ERROR]: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "[LLM Structured Result]: {\n",
      "  \"title\": \"\",\n",
      "  \"author\": \"\",\n",
      "  \"year\": \"\",\n",
      "  \"doi\": \"\",\n",
      "  \"author_keywords\": \"\",\n",
      "  \"country\": \"\",\n",
      "  \"source_journal\": \"\",\n",
      "  \"study_type\": \"\"\n",
      "}\n",
      "   title            : \n",
      "   author           : \n",
      "   year             : \n",
      "   doi              : \n",
      "   author_keywords  : \n",
      "   country          : \n",
      "   source_journal   : \n",
      "   study_type       : \n",
      "\n",
      "--- PDF paper_ID_e4dd1 ---\n",
      "[First Page Text Preview]: \"JMIR Preprints\\nBienefeld et al\\nHuman-AI Teaming in the ICU: A Comparative\\nAnalysis of Data Scientists' and Clinicians\u2019\\nAssessments on AI Augmentation and Automation at\\nWork\\n Nadine Bienefeld, Emanuela Keller, Gudela Grote\\nSubmitted to: Journal of Med\"\n",
      "[LLM ERROR]: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "[LLM Structured Result]: {\n",
      "  \"title\": \"\",\n",
      "  \"author\": \"\",\n",
      "  \"year\": \"\",\n",
      "  \"doi\": \"\",\n",
      "  \"author_keywords\": \"\",\n",
      "  \"country\": \"\",\n",
      "  \"source_journal\": \"\",\n",
      "  \"study_type\": \"\"\n",
      "}\n",
      "   title            : \n",
      "   author           : \n",
      "   year             : \n",
      "   doi              : \n",
      "   author_keywords  : \n",
      "   country          : \n",
      "   source_journal   : \n",
      "   study_type       : \n",
      "\n",
      "--- PDF paper_ID_d3079 ---\n",
      "[First Page Text Preview]: 'JMIR Preprints\\nCha et al\\nAI-Based Tailored Mobile Intervention for Nurse\\nBurnout: Development Study\\n Chiyoung Cha, Aram Cho, Gumhee Baek\\nSubmitted to: Journal of Medical Internet Research\\non: November 02, 2023\\nDisclaimer: \u00a9 The authors. All rights re'\n",
      "[LLM ERROR]: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "[LLM Structured Result]: {\n",
      "  \"title\": \"\",\n",
      "  \"author\": \"\",\n",
      "  \"year\": \"\",\n",
      "  \"doi\": \"\",\n",
      "  \"author_keywords\": \"\",\n",
      "  \"country\": \"\",\n",
      "  \"source_journal\": \"\",\n",
      "  \"study_type\": \"\"\n",
      "}\n",
      "   title            : \n",
      "   author           : \n",
      "   year             : \n",
      "   doi              : \n",
      "   author_keywords  : \n",
      "   country          : \n",
      "   source_journal   : \n",
      "   study_type       : \n",
      "\n",
      "--- PDF paper_ID_e6d59 ---\n",
      "[First Page Text Preview]: 'Proceedings of the Hip Society 2023\\nAppropriateness of Frequently Asked Patient Questions Following\\nTotal Hip Arthroplasty From ChatGPT Compared to\\nArthroplasty-Trained Nurses\\nJeremy A. Dubin, BA a, Sandeep S. Bains, MD, DC, MBA a, Michael J. DeRogat'\n",
      "[LLM ERROR]: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "[LLM Structured Result]: {\n",
      "  \"title\": \"\",\n",
      "  \"author\": \"\",\n",
      "  \"year\": \"\",\n",
      "  \"doi\": \"\",\n",
      "  \"author_keywords\": \"\",\n",
      "  \"country\": \"\",\n",
      "  \"source_journal\": \"\",\n",
      "  \"study_type\": \"\"\n",
      "}\n",
      "   title            : \n",
      "   author           : \n",
      "   year             : \n",
      "   doi              : \n",
      "   author_keywords  : \n",
      "   country          : \n",
      "   source_journal   : \n",
      "   study_type       : \n",
      "\n",
      "--- PDF paper_ID_332b9 ---\n",
      "[First Page Text Preview]: 'Citation: Garcia, C.; Inoue, S.\\nRelabeling for Indoor Localization\\nUsing Stationary Beacons in Nursing\\nCare Facilities. Sensors 2024, 24, 319.\\nhttps://doi.org/10.3390/s24020319\\nAcademic Editor: Boon Giin Lee\\nReceived: 9 December 2023\\nRevised: 31 Dece'\n",
      "[LLM ERROR]: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "[LLM Structured Result]: {\n",
      "  \"title\": \"\",\n",
      "  \"author\": \"\",\n",
      "  \"year\": \"\",\n",
      "  \"doi\": \"\",\n",
      "  \"author_keywords\": \"\",\n",
      "  \"country\": \"\",\n",
      "  \"source_journal\": \"\",\n",
      "  \"study_type\": \"\"\n",
      "}\n",
      "   title            : \n",
      "   author           : \n",
      "   year             : \n",
      "   doi              : \n",
      "   author_keywords  : \n",
      "   country          : \n",
      "   source_journal   : \n",
      "   study_type       : \n",
      "========== End of LLM Extraction Debug ==========\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title [Block 4] Reviewer QA, Correction, Approval of Manifest (v6.2.2)\n",
    "#\n",
    "# ----------- [Block Summary] -----------\n",
    "# - Loads extraction_manifest.csv and ensures all *_votes columns present.\n",
    "# - Prints flagged summary and requires reviewer name/custody.\n",
    "# - Field-by-field correction modal, manual/choice, audit-logs output.\n",
    "# - Outputs final locked manifest, reviewer log, agreement matrix.\n",
    "# - All outputs are hash-logged for audit/forensic fixity.\n",
    "#\n",
    "# ----------- [Version Control] -----------\n",
    "# v6.2.1: Robust *_votes handling, audit hashing, custody modal, reviewer workflow robust for PI/QA use.\n",
    "# v6.2.2: Reviewer QA, Autofix, Correction, & Submission Approval\n",
    "#\n",
    "# ----------- [Block Summary] -----------\n",
    "# - Loads extraction_manifest.csv, parses *_votes JSON\n",
    "# - Auto-confirms a field if \u22652 non-missing sources match LLM (lenient for title/author)\n",
    "# - For title/author: uses fuzzy normalization for consensus (OpenAlex/CrossRef selected if close to LLM)\n",
    "# - Prompts reviewer only on non-consensus fields\n",
    "# - At end, prints and requests reviewer \u201cReady to submit?\u201d approval\n",
    "# - All outputs hash-logged, custody and audit tracked\n",
    "\n",
    "import json, pandas as pd, datetime, hashlib\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def sha256_file(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return hashlib.sha256(f.read()).hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def norm_str(x):\n",
    "    \"\"\" Normalize a string for lenient matching: lowercase, strip, no punct, no space \"\"\"\n",
    "    import re\n",
    "    return re.sub(r\"[\\s\\W_]+\", \"\", str(x or \"\").lower())\n",
    "\n",
    "def fuzzy_ratio(a, b):\n",
    "    \"\"\" Return difflib ratio between two strings (0-100) \"\"\"\n",
    "    return int(SequenceMatcher(None, str(a or \"\"), str(b or \"\")).ratio() * 100)\n",
    "\n",
    "with open(\"pipeline_env.json\", \"r\") as f:\n",
    "    env = json.load(f)\n",
    "OPERATIONAL_DIR = Path(env[\"OPERATIONAL_DIR\"])\n",
    "EXTRACTION_PATH = OPERATIONAL_DIR / \"extraction_manifest.csv\"\n",
    "REVIEW_LOG_PATH = OPERATIONAL_DIR / \"review_correction_log.json\"\n",
    "FINAL_MANIFEST_PATH = OPERATIONAL_DIR / \"final_manifest.csv\"\n",
    "AUDIT_PATH = OPERATIONAL_DIR / \"reviewer_block4_audit.jsonl\"\n",
    "\n",
    "fields = [\"title\", \"author\", \"year\", \"doi\"]\n",
    "methods = [\"llm_raw\", \"grobid\", \"fitz\", \"crossref\", \"openalex\", \"filename\"]\n",
    "\n",
    "def robust_json_parse(val):\n",
    "    if isinstance(val, dict): return val\n",
    "    if pd.isna(val) or str(val).strip() in [\"\", \"{}\", \"nan\", \"None\"]:\n",
    "        return {m:\"\" for m in methods}\n",
    "    try:\n",
    "        js = json.loads(val)\n",
    "        if not isinstance(js, dict): return {m:\"\" for m in methods}\n",
    "        for m in methods:\n",
    "            js.setdefault(m, \"\")\n",
    "        return js\n",
    "    except Exception:\n",
    "        try:\n",
    "            import ast\n",
    "            js = ast.literal_eval(val)\n",
    "            return dict(js) if isinstance(js, dict) else {m:\"\" for m in methods}\n",
    "        except Exception:\n",
    "            return {m:\"\" for m in methods}\n",
    "\n",
    "df = pd.read_csv(EXTRACTION_PATH)\n",
    "for field in fields:\n",
    "    col = f\"{field}_votes\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = [{m:\"\" for m in methods} for _ in range(len(df))]\n",
    "    else:\n",
    "        df[col] = df[col].apply(robust_json_parse)\n",
    "\n",
    "# -------- Consensus/Autofix Step --------------\n",
    "autofix_counter = Counter()\n",
    "needs_manual_idx = []\n",
    "for idx, row in df.iterrows():\n",
    "    auto_decided = {}\n",
    "    for field in fields:\n",
    "        votes = row.get(f\"{field}_votes\", {m:\"\" for m in methods}).copy()\n",
    "        values = [v for v in votes.values() if v and v != \"[Missing]\"]\n",
    "        llm_val = votes.get(\"llm_raw\", \"\")\n",
    "        nonblank = [m for m in methods if votes[m] and votes[m] != \"[Missing]\"]\n",
    "\n",
    "        # Helper: Fuzzy or strict match\n",
    "        def close_enough(a, b, field):\n",
    "            if not a or not b: return False\n",
    "            if field in [\"title\", \"author\"]:\n",
    "                if norm_str(a) == norm_str(b): return True\n",
    "                return fuzzy_ratio(a, b) >= (88 if field == \"title\" else 82) # tunable\n",
    "            else:\n",
    "                return str(a).strip().lower() == str(b).strip().lower()\n",
    "\n",
    "        # For author/title, check if OpenAlex or CrossRef is \"close\" to LLM\n",
    "        preferred_raw = None\n",
    "        for m in [\"openalex\", \"crossref\"]:\n",
    "            if close_enough(votes.get(\"llm_raw\", \"\"), votes.get(m, \"\"), field):\n",
    "                preferred_raw = votes[m]\n",
    "                break\n",
    "\n",
    "        # Consensus: \u22652 methods \"close enough\" to LLM and non-missing OR LLM+OpenAlex/CrossRef is close\n",
    "        match_methods = [m for m in methods if close_enough(llm_val, votes[m], field)]\n",
    "        n_matches = len([k for k in match_methods if votes[k]])\n",
    "\n",
    "        # Ignore filename/fitz if only partial or non-informative (skip as consensus candidates for title/author)\n",
    "        valid_compare_methods = [m for m in methods if m != \"filename\" and votes[m]]\n",
    "\n",
    "        if field in [\"title\", \"author\"]:\n",
    "            # More aggressive autofix for noisy fields\n",
    "            if preferred_raw:\n",
    "                df.loc[idx, f\"{field}_final\"] = preferred_raw\n",
    "                df.loc[idx, f\"{field}_src\"] = \"openalex/crossref\"\n",
    "                auto_decided[field] = True\n",
    "                autofix_counter[field] += 1\n",
    "                continue\n",
    "            if n_matches >= 2 and set(match_methods).intersection(set(valid_compare_methods)):\n",
    "                df.loc[idx, f\"{field}_final\"] = llm_val\n",
    "                df.loc[idx, f\"{field}_src\"] = \"llm_raw\"\n",
    "                auto_decided[field] = True\n",
    "                autofix_counter[field] += 1\n",
    "                continue\n",
    "        else:\n",
    "            if n_matches >= 2:\n",
    "                df.loc[idx, f\"{field}_final\"] = llm_val\n",
    "                df.loc[idx, f\"{field}_src\"] = \"llm_raw\"\n",
    "                auto_decided[field] = True\n",
    "                autofix_counter[field] += 1\n",
    "                continue\n",
    "\n",
    "        # If only one non-missing value, auto-select\n",
    "        if len(nonblank) == 1:\n",
    "            df.loc[idx, f\"{field}_final\"] = votes[nonblank[0]]\n",
    "            df.loc[idx, f\"{field}_src\"] = nonblank[0]\n",
    "            auto_decided[field] = True\n",
    "            autofix_counter[field] += 1\n",
    "            continue\n",
    "\n",
    "        # Too ambiguous or no close match\u2014needs reviewer\n",
    "        if not auto_decided.get(field, False):\n",
    "            needs_manual_idx.append((idx, field))\n",
    "\n",
    "# Second pass: Flag only fields needing review\n",
    "needs_review = set([idx for idx, f in needs_manual_idx])\n",
    "df[\"needs_review\"] = df.index.isin(needs_review)\n",
    "df[\"review_reason\"] = \"\"\n",
    "for idx in range(len(df)):\n",
    "    missing = [f for f in fields if (idx, f) in needs_manual_idx]\n",
    "    df.loc[idx, \"review_reason\"] = \";\".join(f\"{f}_disagree_or_missing\" for f in missing)\n",
    "\n",
    "# --------- Table 2a: Reviewer Correction Summary -----------\n",
    "print(\"\\n--- Table 2a: Reviewer Correction Summary (AFTER AUTOFIX) ---\")\n",
    "needreview = df[df[\"needs_review\"] == True]\n",
    "reason_counter = Counter()\n",
    "for _, row in needreview.iterrows():\n",
    "    for reason in str(row.get(\"review_reason\", \"\")).split(\";\"):\n",
    "        if reason.strip():\n",
    "            reason_counter[reason.split(\"_\")[0]] += 1\n",
    "for f in fields:\n",
    "    print(f\"{f:8}: {reason_counter.get(f,0)} flagged (manual review needed)\")\n",
    "print(f\"{len(needreview)} papers to review (out of {len(df)})\")\n",
    "print(f\"Autofixed fields breakdown: {dict(autofix_counter)}\")\n",
    "\n",
    "# ----------- Reviewer name/custody modal --------------\n",
    "reviewer_name = None\n",
    "while not reviewer_name or len(reviewer_name.strip()) < 2:\n",
    "    reviewer_name = input(\"\\nPlease TYPE YOUR FULL NAME for manifest lock (for audit):\\n> \").strip()\n",
    "\n",
    "result_decision = input(\n",
    "    \"\\nDo you wish to review/correct flagged fields now? [Y/N]: \"\n",
    ").lower().strip()\n",
    "corrections = []\n",
    "\n",
    "if result_decision == \"y\" and len(needreview):\n",
    "    print(\"\\n--- Reviewer Correction: Step through flagged fields ---\")\n",
    "    for idx, row in needreview.iterrows():\n",
    "        pdf_id = row[\"pdf_id\"]\n",
    "        for field in fields:\n",
    "            if f\"{field}_disagree_or_missing\" not in str(row.get(\"review_reason\", \"\")):\n",
    "                continue\n",
    "            votes = row.get(f\"{field}_votes\", {m:\"\" for m in methods})\n",
    "            print(f\"\\n[REVIEW] pdf_id: {pdf_id} | FIELD: {field.upper()} | flagged: {row.get('review_reason','')}\")\n",
    "            for i, method in enumerate(methods):\n",
    "                val_disp = votes.get(method, \"\") if votes.get(method, \"\") else \"[Missing]\"\n",
    "                print(f\"[{chr(65+i)}] {method:<9}: {val_disp}\")\n",
    "            sel = input(f\"Choose value for {field} (A-{chr(65+len(methods)-1)}) or type MANUAL: \").strip()\n",
    "            if sel.lower() == \"manual\":\n",
    "                val = input(f\"Manual value for {field}: \").strip()\n",
    "                df.loc[idx, f\"{field}_final\"] = val\n",
    "                df.loc[idx, f\"{field}_src\"] = \"manual\"\n",
    "                corrections.append(\n",
    "                    {\"pdf_id\": pdf_id, \"field\": field, \"chosen\": val, \"src\": \"manual\", \"reviewer\": reviewer_name}\n",
    "                )\n",
    "            elif len(sel) == 1 and chr(65) <= sel.upper() < chr(65+len(methods)):\n",
    "                chosen_method = methods[ord(sel.upper()) - 65]\n",
    "                val = votes.get(chosen_method, \"\")\n",
    "                df.loc[idx, f\"{field}_final\"] = val\n",
    "                df.loc[idx, f\"{field}_src\"] = chosen_method\n",
    "                corrections.append(\n",
    "                    {\"pdf_id\": pdf_id, \"field\": field, \"chosen\": val, \"src\": chosen_method, \"reviewer\": reviewer_name}\n",
    "                )\n",
    "    print(\"\\n[Reviewer correction input complete.]\")\n",
    "else:\n",
    "    print(\"\\nNo manual review required or corrections skipped.\")\n",
    "\n",
    "# --------- Final Manifest Summary & Ready-to-Submit Step -----------\n",
    "print(\"\\n--- SUMMARY: Final Manifest Table (LOCKED after Review) ---\")\n",
    "finalcols = [\"pdf_id\"] + [f\"{field}_final\" for field in fields] + [\"needs_review\", \"review_reason\"]\n",
    "print(df[finalcols].to_string(index=False, max_colwidth=48))\n",
    "print(\"\\nCOUNT SUMMARY by FIELD source:\")\n",
    "for field in fields:\n",
    "    sources = Counter([str(row.get(f\"{field}_src\", \"\")) for _, row in df.iterrows()])\n",
    "    print(f\"{field:8}: {dict(sources)}\")\n",
    "\n",
    "final_approve = input(\"\\n[REVIEWER FINAL CHECK] Submit this manifest as LOCKED for submission? [Y/N]: \").lower().strip()\n",
    "if final_approve != \"y\":\n",
    "    print(\"Lock/review decision withheld. No submission flagged. Please rerun this after changes if needed.\")\n",
    "else:\n",
    "    print(\"Manifest approved by reviewer for submission. Manifest is now LOCKED in audit log.\")\n",
    "\n",
    "# ---------- Table 5: Extraction Source-Field Agreement Matrix --------\n",
    "print(\"\\n--- Table 5: Extraction Source-Field Agreement Matrix ---\")\n",
    "method_counts = pd.DataFrame(0, index=fields, columns=methods)\n",
    "for idx, row in df.iterrows():\n",
    "    for field in fields:\n",
    "        src = str(row.get(f\"{field}_src\", \"\")).lower()\n",
    "        if src in method_counts.columns:\n",
    "            method_counts.at[field, src] += 1\n",
    "print(method_counts.to_string())\n",
    "\n",
    "# ------------- Write reviewer-locked manifest/log (hash-logged) -------------\n",
    "df.to_csv(FINAL_MANIFEST_PATH, index=False)\n",
    "with open(REVIEW_LOG_PATH, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"reviewer\": reviewer_name,\n",
    "        \"timestamp_utc\": str(datetime.datetime.utcnow()) + \"Z\",\n",
    "        \"timestamp_nzdt\": str(datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=12))),),\n",
    "        \"changes\": corrections,\n",
    "        \"final_approved\": final_approve == \"y\"\n",
    "    }, f, indent=2)\n",
    "\n",
    "out_hashes = {\n",
    "    \"final_manifest.csv.sha256\": sha256_file(FINAL_MANIFEST_PATH),\n",
    "    \"review_correction_log.json.sha256\": sha256_file(REVIEW_LOG_PATH)\n",
    "}\n",
    "for out, hashv in out_hashes.items():\n",
    "    with open(OPERATIONAL_DIR / out, \"w\") as f:\n",
    "        f.write(hashv or \"\")\n",
    "\n",
    "# Minimal audit log\n",
    "with open(AUDIT_PATH, \"a\") as f:\n",
    "    f.write(json.dumps({\n",
    "        \"step\": \"block4_reviewer_approval\",\n",
    "        \"timestamp_utc\": str(datetime.datetime.utcnow()) + \"Z\",\n",
    "        \"timestamp_nzdt\": str(datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=12))),),\n",
    "        \"outputs\": {k: str(OPERATIONAL_DIR / k) for k in out_hashes},\n",
    "        \"hashes\": out_hashes,\n",
    "        \"reviewer\": reviewer_name,\n",
    "        \"final_approved\": final_approve == \"y\"\n",
    "    }) + \"\\n\")\n",
    "\n",
    "print(f\"\\n[Final manifest saved to {FINAL_MANIFEST_PATH}]\")\n",
    "print(\"[Review correction log saved to review_correction_log.json]\")\n",
    "print(f\"[SHA256 hashes written for outputs. Audit log updated at: {AUDIT_PATH}]\")\n",
    "print(\"--- End Block 4 ---\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DF2A31168An",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746760531797,
     "user_tz": -720,
     "elapsed": 45157,
     "user": {
      "displayName": "Nurse David",
      "userId": "07956094516023546703"
     }
    },
    "outputId": "dbdf0920-96ca-489b-9487-a85059376421"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-82-d6cc2d1d6ecf>:131: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2024' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[idx, f\"{field}_final\"] = llm_val\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Table 2a: Reviewer Correction Summary (AFTER AUTOFIX) ---\n",
      "title   : 0 flagged (manual review needed)\n",
      "author  : 3 flagged (manual review needed)\n",
      "year    : 1 flagged (manual review needed)\n",
      "doi     : 0 flagged (manual review needed)\n",
      "3 papers to review (out of 4)\n",
      "Autofixed fields breakdown: {'title': 4, 'year': 3, 'doi': 4, 'author': 1}\n",
      "\n",
      "Please TYPE YOUR FULL NAME for manifest lock (for audit):\n",
      "> David Brydon\n",
      "\n",
      "Do you wish to review/correct flagged fields now? [Y/N]: Y\n",
      "\n",
      "--- Reviewer Correction: Step through flagged fields ---\n",
      "\n",
      "[REVIEW] pdf_id: pdfid_0391138757b3 | FIELD: AUTHOR | flagged: author_disagree_or_missing\n",
      "[A] llm_raw  : [Missing]\n",
      "[B] grobid   : Mohammad Mengyang Yin\n",
      "[C] fitz     : [Missing]\n",
      "[D] crossref : Alkhalaf; Yin; Deng; Chang; Yu\n",
      "[E] openalex : Mohammad Alkhalaf; Mengyang Yin; Chao Deng; Hui\u2010Chen Chang; Ping Yu\n",
      "[F] filename : Copy of Alkhalaf et al.\n",
      "Choose value for author (A-F) or type MANUAL: e\n",
      "\n",
      "[REVIEW] pdf_id: pdfid_e4dd16ac4a87 | FIELD: AUTHOR | flagged: author_disagree_or_missing\n",
      "[A] llm_raw  : Nadine Bienefeld;Emanuela Keller;Gudela Grote\n",
      "[B] grobid   : Nadine Emanuela Keller\n",
      "[C] fitz     : [Missing]\n",
      "[D] crossref : Bienefeld; Keller; Grote\n",
      "[E] openalex : [Missing]\n",
      "[F] filename : Copy of Bienefeld et al.\n",
      "Choose value for author (A-F) or type MANUAL: a\n",
      "\n",
      "[REVIEW] pdf_id: pdfid_d3079134f529 | FIELD: AUTHOR | flagged: author_disagree_or_missing;year_disagree_or_missing\n",
      "[A] llm_raw  : Chiyoung Cha;Aram Cho;Gumhee Baek\n",
      "[B] grobid   : Chiyoung Aram Cho\n",
      "[C] fitz     : [Missing]\n",
      "[D] crossref : Cho; Cha; Baek\n",
      "[E] openalex : [Missing]\n",
      "[F] filename : Copy of Cho et al.\n",
      "Choose value for author (A-F) or type MANUAL: a\n",
      "\n",
      "[REVIEW] pdf_id: pdfid_d3079134f529 | FIELD: YEAR | flagged: author_disagree_or_missing;year_disagree_or_missing\n",
      "[A] llm_raw  : 2023\n",
      "[B] grobid   : [Missing]\n",
      "[C] fitz     : [Missing]\n",
      "[D] crossref : 2024\n",
      "[E] openalex : [Missing]\n",
      "[F] filename : 2024\n",
      "Choose value for year (A-F) or type MANUAL: f\n",
      "\n",
      "[Reviewer correction input complete.]\n",
      "\n",
      "--- SUMMARY: Final Manifest Table (LOCKED after Review) ---\n",
      "            pdf_id                                      title_final                                     author_final year_final                  doi_final  needs_review                                    review_reason\n",
      "pdfid_0391138757b3 Machine Learning Model to Extract Malnutritio... Mohammad Alkhalaf; Mengyang Yin; Chao Deng; H...       2024         10.3233/shti231240          True                       author_disagree_or_missing\n",
      "pdfid_e4dd16ac4a87 Human-AI Teaming in the ICU: A Comparative An...    Nadine Bienefeld;Emanuela Keller;Gudela Grote       2023              10.2196/50130          True                       author_disagree_or_missing\n",
      "pdfid_d3079134f529 AI-Based Tailored Mobile Intervention for Nur...                Chiyoung Cha;Aram Cho;Gumhee Baek       2024              10.2196/54029          True author_disagree_or_missing;year_disagree_or_m...\n",
      "pdfid_e6d59a511390 Appropriateness of Frequently Asked Patient Q... Jeremy A. Dubin; Sandeep S. Bains; Michael J....       2024 10.1016/j.arth.2024.04.020         False                                                 \n",
      "\n",
      "COUNT SUMMARY by FIELD source:\n",
      "title   : {'openalex/crossref': 2, 'llm_raw': 2}\n",
      "author  : {'openalex': 1, 'llm_raw': 2, 'openalex/crossref': 1}\n",
      "year    : {'llm_raw': 3, 'filename': 1}\n",
      "doi     : {'llm_raw': 2, 'crossref': 2}\n",
      "\n",
      "[REVIEWER FINAL CHECK] Submit this manifest as LOCKED for submission? [Y/N]: Y\n",
      "Manifest approved by reviewer for submission. Manifest is now LOCKED in audit log.\n",
      "\n",
      "--- Table 5: Extraction Source-Field Agreement Matrix ---\n",
      "        llm_raw  grobid  fitz  crossref  openalex  filename\n",
      "title         2       0     0         0         0         0\n",
      "author        2       0     0         0         1         0\n",
      "year          3       0     0         0         0         1\n",
      "doi           2       0     0         2         0         0\n",
      "\n",
      "[Final manifest saved to /content/drive/My Drive/Pilot/Nurse-AI_ScR_250509_1448/operational/final_manifest.csv]\n",
      "[Review correction log saved to review_correction_log.json]\n",
      "[SHA256 hashes written for outputs. Audit log updated at: /content/drive/My Drive/Pilot/Nurse-AI_ScR_250509_1448/operational/reviewer_block4_audit.jsonl]\n",
      "--- End Block 4 ---\n"
     ]
    }
   ]
  }
 ]
}
